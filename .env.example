# AI Configuration
AI_API="https://api.xibe.app/openai"
AI_KEY=your_ai_api_key_here

# Two-Stage AI Models Configuration
# Stage 1 (Agent 1): Individual File Analysis Model - focuses on security & hardcoded values
ANALYSIS_MODEL=deepseek
ANALYSIS_FALLBACK=qwen-coder

# Stage 2 (Agent 2): Review Synthesis Model - creates comprehensive final review
COMMENT_MODEL=openai-large
COMMENT_FALLBACK=mistral

# Legacy Model (for backward compatibility and model selection)
# This model is used for automatic model selection based on PR size
MODEL_ID=openai-large

# GitHub Configuration
GITHUB_APP_ID=your_github_app_id
# GitHub Private Key - Copy the entire private key from your GitHub App settings
# Format: -----BEGIN RSA PRIVATE KEY-----\nMIIEogIBAAKCAQE...\n-----END RSA PRIVATE KEY-----
GITHUB_PRIVATE_KEY=-----BEGIN RSA PRIVATE KEY-----\nMIIEogIBAAKCAQE...\n-----END RSA PRIVATE KEY-----
GITHUB_TOKEN=your_github_token
WEBHOOK_SECRET=your_webhook_secret

# Bot Configuration
BOT_USERNAME=Xibe-review
PORT=3000

# Redis Configuration (for webhook logging)
UPSTASH_REDIS_REST_URL=your_redis_url
UPSTASH_REDIS_REST_TOKEN=your_redis_token

# Available Models for ANALYSIS_MODEL:
# - deepseek (recommended for analysis - excellent reasoning)
# - qwen-coder (specialized for code understanding)
# - openai-reasoning (advanced reasoning)
# - openai-large (comprehensive analysis)

# Available Models for COMMENT_MODEL:
# - openai-large (recommended for comments - most capable)
# - mistral (balanced performance)
# - gemini (fast and efficient)
# - openai (fast processing)

# Fallback Models (used when primary models fail):
# - ANALYSIS_FALLBACK: qwen-coder, mistral, openai
# - COMMENT_FALLBACK: mistral, gemini, openai

# E2B Agent Mode
E2B_ENABLED=false
E2B_API_KEY=your_e2b_api_key_here
E2B_TIMEOUT=300000